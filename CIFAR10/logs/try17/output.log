LR_Gen = 0.0002	LR_Disc = 8e-06	z_dim = 64	batch_size = 32	features_d = 100	features_g = 300
10:12:31.123202	Epoch [1/10]	Batch [1/313]	Loss D: 0.8377	loss G: 1.1975
10:12:39.281956	Epoch [1/10]	Batch [63/313]	Loss D: 2.9807	loss G: 0.0276
10:12:47.064835	Epoch [1/10]	Batch [125/313]	Loss D: 2.3708	loss G: 0.0987
10:12:54.863238	Epoch [1/10]	Batch [187/313]	Loss D: 1.4454	loss G: 0.4597
10:13:02.664333	Epoch [1/10]	Batch [249/313]	Loss D: 0.7157	loss G: 1.1404
10:13:10.471397	Epoch [1/10]	Batch [311/313]	Loss D: 1.0176	loss G: 0.7492
10:13:20.769428	Epoch [2/10]	Batch [1/313]	Loss D: 0.8231	loss G: 1.4803
10:13:29.028917	Epoch [2/10]	Batch [63/313]	Loss D: 1.4561	loss G: 0.4172
10:13:36.819939	Epoch [2/10]	Batch [125/313]	Loss D: 1.2156	loss G: 0.6052
10:13:44.644284	Epoch [2/10]	Batch [187/313]	Loss D: 1.2208	loss G: 0.4705
10:13:52.464013	Epoch [2/10]	Batch [249/313]	Loss D: 1.1122	loss G: 0.5874
10:14:00.305064	Epoch [2/10]	Batch [311/313]	Loss D: 0.7141	loss G: 0.9941
10:14:10.390460	Epoch [3/10]	Batch [1/313]	Loss D: 0.9698	loss G: 0.8566
10:14:18.583415	Epoch [3/10]	Batch [63/313]	Loss D: 0.5152	loss G: 1.7277
10:14:26.393639	Epoch [3/10]	Batch [125/313]	Loss D: 0.6222	loss G: 1.3304
10:14:34.203725	Epoch [3/10]	Batch [187/313]	Loss D: 0.9535	loss G: 0.8187
10:14:42.072149	Epoch [3/10]	Batch [249/313]	Loss D: 0.9209	loss G: 0.6889
10:14:49.890817	Epoch [3/10]	Batch [311/313]	Loss D: 0.5433	loss G: 1.2654
10:15:00.230584	Epoch [4/10]	Batch [1/313]	Loss D: 0.6276	loss G: 1.0889
10:15:08.380376	Epoch [4/10]	Batch [63/313]	Loss D: 1.0903	loss G: 0.5508
10:15:16.222874	Epoch [4/10]	Batch [125/313]	Loss D: 0.8652	loss G: 0.6741
10:15:24.082246	Epoch [4/10]	Batch [187/313]	Loss D: 1.1307	loss G: 0.5878
10:15:31.904587	Epoch [4/10]	Batch [249/313]	Loss D: 0.7251	loss G: 0.8248
10:15:39.722692	Epoch [4/10]	Batch [311/313]	Loss D: 0.8467	loss G: 0.7466
10:15:50.179747	Epoch [5/10]	Batch [1/313]	Loss D: 0.8532	loss G: 0.7156
10:15:58.367516	Epoch [5/10]	Batch [63/313]	Loss D: 0.9076	loss G: 0.6432
10:16:06.183157	Epoch [5/10]	Batch [125/313]	Loss D: 0.8241	loss G: 0.6607
10:16:14.028904	Epoch [5/10]	Batch [187/313]	Loss D: 0.9496	loss G: 0.6179
10:16:21.872820	Epoch [5/10]	Batch [249/313]	Loss D: 0.5903	loss G: 0.9554
10:16:29.707105	Epoch [5/10]	Batch [311/313]	Loss D: 0.7515	loss G: 0.7396
10:16:40.574319	Epoch [6/10]	Batch [1/313]	Loss D: 0.7534	loss G: 0.7148
10:16:48.758875	Epoch [6/10]	Batch [63/313]	Loss D: 0.5537	loss G: 0.9031
10:16:56.576278	Epoch [6/10]	Batch [125/313]	Loss D: 0.7064	loss G: 0.8264
10:17:04.493198	Epoch [6/10]	Batch [187/313]	Loss D: 0.7554	loss G: 0.8228
10:17:12.319786	Epoch [6/10]	Batch [249/313]	Loss D: 0.6538	loss G: 0.9339
10:17:20.160776	Epoch [6/10]	Batch [311/313]	Loss D: 0.6476	loss G: 0.8092
10:17:30.506706	Epoch [7/10]	Batch [1/313]	Loss D: 0.6942	loss G: 0.8119
10:17:38.691874	Epoch [7/10]	Batch [63/313]	Loss D: 1.0916	loss G: 0.3835
10:17:46.506868	Epoch [7/10]	Batch [125/313]	Loss D: 0.9222	loss G: 0.5142
10:17:54.329218	Epoch [7/10]	Batch [187/313]	Loss D: 0.8943	loss G: 0.5418
10:18:02.151290	Epoch [7/10]	Batch [249/313]	Loss D: 0.8887	loss G: 0.5613
10:18:09.978629	Epoch [7/10]	Batch [311/313]	Loss D: 0.7991	loss G: 0.5933
10:18:20.322986	Epoch [8/10]	Batch [1/313]	Loss D: 0.8353	loss G: 0.5828
10:18:28.466982	Epoch [8/10]	Batch [63/313]	Loss D: 0.8488	loss G: 0.5670
10:18:36.300889	Epoch [8/10]	Batch [125/313]	Loss D: 0.8194	loss G: 0.6102
10:18:44.130598	Epoch [8/10]	Batch [187/313]	Loss D: 0.7479	loss G: 0.6787
10:18:51.954727	Epoch [8/10]	Batch [249/313]	Loss D: 0.7958	loss G: 0.6131
10:18:59.829192	Epoch [8/10]	Batch [311/313]	Loss D: 0.8289	loss G: 0.6097
10:19:09.946047	Epoch [9/10]	Batch [1/313]	Loss D: 0.8011	loss G: 0.6123
10:19:18.078585	Epoch [9/10]	Batch [63/313]	Loss D: 0.8226	loss G: 0.5923
10:19:25.894333	Epoch [9/10]	Batch [125/313]	Loss D: 0.8061	loss G: 0.6146
10:19:33.716209	Epoch [9/10]	Batch [187/313]	Loss D: 0.7798	loss G: 0.6235
10:19:41.552237	Epoch [9/10]	Batch [249/313]	Loss D: 0.7660	loss G: 0.6372
10:19:49.438127	Epoch [9/10]	Batch [311/313]	Loss D: 0.7679	loss G: 0.6443
10:20:01.334560	Epoch [10/10]	Batch [1/313]	Loss D: 0.7781	loss G: 0.6472
10:20:09.560915	Epoch [10/10]	Batch [63/313]	Loss D: 0.7693	loss G: 0.6561
10:20:17.442587	Epoch [10/10]	Batch [125/313]	Loss D: 0.7343	loss G: 0.6753
10:20:25.325256	Epoch [10/10]	Batch [187/313]	Loss D: 0.7855	loss G: 0.6197
10:20:33.179153	Epoch [10/10]	Batch [249/313]	Loss D: 0.7611	loss G: 0.6395
10:20:41.016216	Epoch [10/10]	Batch [311/313]	Loss D: 0.7680	loss G: 0.6279
